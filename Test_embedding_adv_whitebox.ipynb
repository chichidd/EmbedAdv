{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "# from transformers import AutoTokenizer, AutoModel\n",
    "from transformers import DistilBertTokenizerFast, DistilBertForSequenceClassification, Trainer, TrainingArguments\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "import pickle\n",
    "from utils import EncodingDataset, get_stopwords\n",
    "from pathlib import Path\n",
    "import itertools\n",
    "from termcolor import colored\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fa167793170>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(2020)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# other option: imdb_data = load_dataset(\"imdb\")\n",
    "def read_imdb_split(split_dir):\n",
    "    split_dir = Path(split_dir)\n",
    "    texts = []\n",
    "    labels = []\n",
    "    for label_dir in [\"pos\", \"neg\"]:\n",
    "        for text_file in (split_dir/label_dir).iterdir():\n",
    "            texts.append(text_file.read_text())\n",
    "            labels.append(0 if label_dir is \"neg\" else 1)\n",
    "\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-uncased were not used when initializing DistilBertForSequenceClassification: ['vocab_transform.weight', 'vocab_transform.bias', 'vocab_layer_norm.weight', 'vocab_layer_norm.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-uncased and are newly initialized: ['pre_classifier.weight', 'pre_classifier.bias', 'classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.92      0.92     12443\n",
      "           1       0.92      0.92      0.92     12557\n",
      "\n",
      "    accuracy                           0.92     25000\n",
      "   macro avg       0.92      0.92      0.92     25000\n",
      "weighted avg       0.92      0.92      0.92     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained('distilbert-base-uncased')\n",
    "model = DistilBertForSequenceClassification.from_pretrained('distilbert-base-uncased')\n",
    "model_untrained = copy.deepcopy(model)\n",
    "\n",
    "model.load_state_dict(torch.load(\"distilledBERT.pt\"))\n",
    "model.eval()\n",
    "model_untrained.to(device)\n",
    "model.to(device)\n",
    "\n",
    "TRAIN = False\n",
    "TEST = True\n",
    "if TRAIN:\n",
    "    train_texts, train_labels = read_imdb_split('aclImdb/train')\n",
    "    train_texts, val_texts, train_labels, val_labels = train_test_split(train_texts, train_labels, test_size=.2)\n",
    "    train_encodings = tokenizer(train_texts, truncation=True, padding=True)\n",
    "    train_dataset = EncodingDataset(train_encodings, train_labels)\n",
    "#     val_encodings = tokenizer(val_texts, truncation=True, padding=True)\n",
    "#     val_dataset = EncodingDataset(val_encodings, val_labels)\n",
    "    model.train()\n",
    "    train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "    optim = torch.optim.AdamW(model.parameters(), lr=5e-5)\n",
    "\n",
    "    for epoch in range(3):\n",
    "        for batch in train_loader:\n",
    "            optim.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs[0]\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "\n",
    "    model.eval()\n",
    "\n",
    "if TEST:\n",
    "    test_texts, test_labels = read_imdb_split('aclImdb/test')\n",
    "    test_encodings = tokenizer(test_texts, truncation=True, padding=True)\n",
    "    test_dataset = EncodingDataset(test_encodings, test_labels)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)\n",
    "    outputs_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i, batch in enumerate(test_loader):\n",
    "\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            outputs_list.append(torch.argmax(outputs[1],dim=1).cpu().detach().numpy())\n",
    "\n",
    "    pred = np.concatenate(outputs_list)\n",
    "    print(classification_report(pred, test_labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Black box using Importance score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select an example for play\n",
    "example_idx = 2020\n",
    "example_text = test_texts[example_idx]\n",
    "with torch.no_grad():\n",
    "    example_tokenized = tokenizer(example_text, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    leave_1_token = get_leave_1_token(example_tokenized)\n",
    "    example_origin_cls_emb = model.base_model(**example_tokenized)[0][:,0,:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leave_1_token(tokenized):\n",
    "    '''\n",
    "    Replace every token (i.e. tokenized word) in the tokenized sentence by '[UNK]' (unkwown token).\n",
    "    '''\n",
    "    output = {}\n",
    "    token_num = tokenized['input_ids'].shape[1]\n",
    "    output['input_ids'] = tokenized['input_ids'].repeat(token_num-2,1)\n",
    "    output['attention_mask'] = tokenized['attention_mask'].repeat(token_num-2,1)\n",
    "    for i, input_ids1 in enumerate(output['input_ids']):\n",
    "        output['input_ids'][i, i+1] = 100 # make it to [UNK]\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_importance_score_from_pred_probs(origin_token, leave_1_token, model):\n",
    "    '''\n",
    "    TextFooler importance score.\n",
    "    Dependant on the fine-tuned classification model.\n",
    "    Not worthy for embedding adv.\n",
    "    Just a demo.\n",
    "    '''\n",
    "    # no enough GPU memory\n",
    "    with torch.no_grad(): # only need output probability\n",
    "        orig_probs = model(**origin_token)[0]\n",
    "        orig_label = torch.argmax(orig_probs)\n",
    "        orig_prob = torch.max(orig_probs)\n",
    "        \n",
    "        leave_1_probs = model(**leave_1_token)[0]\n",
    "        leave_1_probs_argmax = torch.argmax(leave_1_probs, dim=-1)\n",
    "        \n",
    "        import_scores = (orig_prob - leave_1_probs[:, orig_label]).cpu().numpy()\n",
    "        \n",
    "        import_scores += ((leave_1_probs_argmax != orig_label).float() * \n",
    "                         (leave_1_probs.max(dim=-1)[0] - torch.index_select(orig_probs, 1, leave_1_probs_argmax).reshape(-1))).cpu().numpy()\n",
    "        return import_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_importance_score_from_cls_emb(origin_token, leave_1_token, model, lamb=1):\n",
    "    '''\n",
    "    importance score for classification embedding: \n",
    "    MSE(leave_1_cls_emb, origin_cls_emb) - lamb * cosine_similarity(leave_1_cls_emb, origin_cls_emb)\n",
    "    ========= Remark ==========\n",
    "    seems like lamb has no influence on the import_scores, may because the similarity are close...\n",
    "    '''\n",
    "    # no enough GPU memory\n",
    "    with torch.no_grad(): # only need output probability\n",
    "        example_origin_cls_emb = model.base_model(**origin_token)[0][0][0]\n",
    "        leave_1_cls_emb = model.base_model(**leave_1_token)[0][:,0,:]\n",
    "        cos_sim = torch.matmul(leave_1_cls_emb, example_origin_cls_emb)/torch.norm(leave_1_cls_emb, dim=1)/torch.norm(example_origin_cls_emb)#.reshape(-1, 1))\n",
    "        MSE = torch.norm(example_origin_cls_emb - leave_1_cls_emb, dim=1)\n",
    "        import_scores = MSE - lamb*cos_sim\n",
    "        \n",
    "        return import_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_perturb_index(import_scores, threshold=None, select_n=None, get_important=True):\n",
    "    '''\n",
    "    Get some most important words.\n",
    "    we can set a treshold of selected words' score (using threshold), or a number of selected words(using select_n)\n",
    "    '''\n",
    "    tokenid_perturb = []\n",
    "    if threshold is not None:\n",
    "        for idx, score in sorted(enumerate(import_scores), key=lambda x: x[1], reverse=get_important):\n",
    "            try:\n",
    "                if score > threshold: # and text_ls[idx] not in stop_words_set:\n",
    "                    tokenid_perturb.append(idx)\n",
    "            except:\n",
    "                print(idx)\n",
    "        tokenid_perturb = np.array(tokenid_perturb)\n",
    "    elif select_n is not None:\n",
    "        \n",
    "        tokenid_perturb = np.array(sorted(enumerate(import_scores), key=lambda x: x[1], reverse=get_important))[:select_n, 0]\n",
    "    \n",
    "    return tokenid_perturb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_scores_pred_probs = compute_importance_score_from_pred_probs(example_tokenized, leave_1_token, model)\n",
    "tokenid_perturb_ids_pred_probs = get_index_perturb_index(import_scores_pred_probs, select_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] after the atomic bomb hits hiroshima , charred bodies lie all around , def ##or ##med victims attempt to communicate with relatives who can ' t even recognize them , and one person after another dies of radiation sickness . this black and white film , however sad and scary , is not without humor . the story revolves around a young woman ya ##su ##ko , who was hit by black rain after the explosion . she is trying to get married , but everyone keeps dying , and people are worried the same will happen to her . after finding a suitable mate ( who is losing his mind after being in the war for too long ) , she ends up showing signs of radiation sickness . this \u001b[31mfilm[1.39]\u001b[0m \u001b[31mis[1.48]\u001b[0m \u001b[31ma[4.19]\u001b[0m \u001b[31mgreat[3.38]\u001b[0m \u001b[31mportrayal[0.83]\u001b[0m of the atomic attacks on japan , it will fright ##en you , and will perhaps make you \u001b[31mcry[0.74]\u001b[0m . the \u001b[31macting[1.11]\u001b[0m \u001b[31mis[1.21]\u001b[0m \u001b[31mgood[0.77]\u001b[0m \u001b[31m,[0.77]\u001b[0m not overly dramatic like many other w ##w ##2 films that have been made . [SEP] "
     ]
    }
   ],
   "source": [
    "for i,w  in enumerate(example_tokenized['input_ids'][0]):\n",
    "    if i in tokenid_perturb_ids_pred_probs:\n",
    "        print(colored(tokenizer.decode(w.reshape(1).cpu().numpy()) + \"[{:.2f}]\".format(import_scores_pred_probs[i].item()) , 'red'), end=\" \")\n",
    "    else:\n",
    "        print(tokenizer.decode(w.reshape(1).cpu().numpy()), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "import_scores_cls_emb = compute_importance_score_from_cls_emb(example_tokenized, leave_1_token, model, lamb=0)\n",
    "tokenid_perturb_ids_cls_emb = get_index_perturb_index(import_scores_cls_emb, select_n=10, get_important=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CLS] after the atomic bomb hits hiroshima , charred bodies lie all around , def ##or ##med victims attempt to communicate with relatives who can ' t even recognize them , and one person after another dies of radiation sickness . this black and white film , however sad and scary \u001b[31m,[2.46]\u001b[0m \u001b[31mis[2.79]\u001b[0m \u001b[31mnot[4.13]\u001b[0m \u001b[31mwithout[12.79]\u001b[0m humor . the story revolves around a young woman ya ##su ##ko , who was hit by black rain after the explosion . she is trying to get married , but everyone keeps dying , and people are worried the same will happen to her . after finding a suitable mate ( who is losing his mind after being in the war for too long ) , she ends up showing signs of radiation sickness . this \u001b[31mfilm[3.66]\u001b[0m \u001b[31mis[3.63]\u001b[0m \u001b[31ma[9.59]\u001b[0m \u001b[31mgreat[7.87]\u001b[0m portrayal of the atomic attacks on japan , it will fright ##en you , and will perhaps make you cry . the \u001b[31macting[2.76]\u001b[0m \u001b[31mis[3.16]\u001b[0m good , not overly dramatic like many other w ##w ##2 films that have been made . [SEP] "
     ]
    }
   ],
   "source": [
    "for i,w  in enumerate(example_tokenized['input_ids'][0]):\n",
    "    if i in tokenid_perturb_ids_cls_emb:\n",
    "        print(colored(tokenizer.decode(w.reshape(1).cpu().numpy()) + \"[{:.2f}]\".format(import_scores_cls_emb[i].item()), 'red'), end=\" \")\n",
    "    else:\n",
    "        print(tokenizer.decode(w.reshape(1).cpu().numpy()), end=\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_embedding = model.base_model.get_input_embeddings().num_embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = torch.rand([num_embedding,1]).requires_grad_(True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_embeddings = model.base_model.get_input_embeddings()(torch.tensor([list(np.arange(num_embedding))]).long().to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([30522, 768])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mul(torch.softmax(z, dim=0), input_embeddings.squeeze()).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA out of memory. Tried to allocate 41.65 GiB (GPU 0; 11.91 GiB total capacity; 1.54 GiB already allocated; 9.69 GiB free; 1.61 GiB reserved in total by PyTorch)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-92-6321d8d11ed8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbase_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs_embeds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    503\u001b[0m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_hidden_states\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 505\u001b[0;31m             \u001b[0mreturn_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreturn_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    506\u001b[0m         )\n\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    326\u001b[0m             layer_outputs = layer_module(\n\u001b[0;32m--> 327\u001b[0;31m                 \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhidden_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattn_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    328\u001b[0m             )\n\u001b[1;32m    329\u001b[0m             \u001b[0mhidden_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, attn_mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    267\u001b[0m             \u001b[0mmask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattn_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m             \u001b[0mhead_mask\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhead_mask\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m             \u001b[0moutput_attentions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_attentions\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m         )\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput_attentions\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    530\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    531\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 532\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    533\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/nlp/lib/python3.7/site-packages/transformers/modeling_distilbert.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, query, key, value, mask, head_mask, output_attentions)\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m         \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_per_head\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, dim_per_head)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m         \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, k_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask_reshp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_as\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, k_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mscores\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"inf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# (bs, n_heads, q_length, k_length)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA out of memory. Tried to allocate 41.65 GiB (GPU 0; 11.91 GiB total capacity; 1.54 GiB already allocated; 9.69 GiB free; 1.61 GiB reserved in total by PyTorch)"
     ]
    }
   ],
   "source": [
    "model.base_model(inputs_embeds=input_embeddings[:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/tian/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /home/tian/nltk_data...\n",
      "[nltk_data]   Unzipping taggers/averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = nltk.word_tokenize(example_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('After', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('atomic', 'JJ'),\n",
       " ('bomb', 'NN'),\n",
       " ('hits', 'NNS'),\n",
       " ('Hiroshima', 'NNP'),\n",
       " (',', ','),\n",
       " ('charred', 'VBD'),\n",
       " ('bodies', 'NNS'),\n",
       " ('lie', 'VBP'),\n",
       " ('all', 'DT'),\n",
       " ('around', 'RB'),\n",
       " (',', ','),\n",
       " ('deformed', 'VBD'),\n",
       " ('victims', 'NNS'),\n",
       " ('attempt', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('communicate', 'VB'),\n",
       " ('with', 'IN'),\n",
       " ('relatives', 'NNS'),\n",
       " ('who', 'WP'),\n",
       " ('ca', 'MD'),\n",
       " (\"n't\", 'RB'),\n",
       " ('even', 'RB'),\n",
       " ('recognize', 'VB'),\n",
       " ('them', 'PRP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('one', 'CD'),\n",
       " ('person', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('another', 'DT'),\n",
       " ('dies', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('radiation', 'NN'),\n",
       " ('sickness', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('black', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('white', 'JJ'),\n",
       " ('film', 'NN'),\n",
       " (',', ','),\n",
       " ('however', 'RB'),\n",
       " ('sad', 'JJ'),\n",
       " ('and', 'CC'),\n",
       " ('scary', 'JJ'),\n",
       " (',', ','),\n",
       " ('is', 'VBZ'),\n",
       " ('not', 'RB'),\n",
       " ('without', 'IN'),\n",
       " ('humor', 'NN'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('story', 'NN'),\n",
       " ('revolves', 'VBZ'),\n",
       " ('around', 'RP'),\n",
       " ('a', 'DT'),\n",
       " ('young', 'JJ'),\n",
       " ('woman', 'NN'),\n",
       " ('Yasuko', 'NNP'),\n",
       " (',', ','),\n",
       " ('who', 'WP'),\n",
       " ('was', 'VBD'),\n",
       " ('hit', 'VBN'),\n",
       " ('by', 'IN'),\n",
       " ('black', 'JJ'),\n",
       " ('rain', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('explosion', 'NN'),\n",
       " ('.', '.'),\n",
       " ('She', 'PRP'),\n",
       " ('is', 'VBZ'),\n",
       " ('trying', 'VBG'),\n",
       " ('to', 'TO'),\n",
       " ('get', 'VB'),\n",
       " ('married', 'JJ'),\n",
       " (',', ','),\n",
       " ('but', 'CC'),\n",
       " ('everyone', 'NN'),\n",
       " ('keeps', 'VBZ'),\n",
       " ('dying', 'VBG'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('people', 'NNS'),\n",
       " ('are', 'VBP'),\n",
       " ('worried', 'VBN'),\n",
       " ('the', 'DT'),\n",
       " ('same', 'JJ'),\n",
       " ('will', 'MD'),\n",
       " ('happen', 'VB'),\n",
       " ('to', 'TO'),\n",
       " ('her', 'PRP$'),\n",
       " ('.', '.'),\n",
       " ('After', 'IN'),\n",
       " ('finding', 'VBG'),\n",
       " ('a', 'DT'),\n",
       " ('suitable', 'JJ'),\n",
       " ('mate', 'NN'),\n",
       " ('(', '('),\n",
       " ('who', 'WP'),\n",
       " ('is', 'VBZ'),\n",
       " ('losing', 'VBG'),\n",
       " ('his', 'PRP$'),\n",
       " ('mind', 'NN'),\n",
       " ('after', 'IN'),\n",
       " ('being', 'VBG'),\n",
       " ('in', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('war', 'NN'),\n",
       " ('for', 'IN'),\n",
       " ('too', 'RB'),\n",
       " ('long', 'RB'),\n",
       " (')', ')'),\n",
       " (',', ','),\n",
       " ('she', 'PRP'),\n",
       " ('ends', 'VBZ'),\n",
       " ('up', 'RP'),\n",
       " ('showing', 'VBG'),\n",
       " ('signs', 'NNS'),\n",
       " ('of', 'IN'),\n",
       " ('radiation', 'NN'),\n",
       " ('sickness', 'NN'),\n",
       " ('.', '.'),\n",
       " ('This', 'DT'),\n",
       " ('film', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('a', 'DT'),\n",
       " ('great', 'JJ'),\n",
       " ('portrayal', 'NN'),\n",
       " ('of', 'IN'),\n",
       " ('the', 'DT'),\n",
       " ('atomic', 'JJ'),\n",
       " ('attacks', 'NNS'),\n",
       " ('on', 'IN'),\n",
       " ('Japan', 'NNP'),\n",
       " (',', ','),\n",
       " ('it', 'PRP'),\n",
       " ('will', 'MD'),\n",
       " ('frighten', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " (',', ','),\n",
       " ('and', 'CC'),\n",
       " ('will', 'MD'),\n",
       " ('perhaps', 'RB'),\n",
       " ('make', 'VB'),\n",
       " ('you', 'PRP'),\n",
       " ('cry', 'VB'),\n",
       " ('.', '.'),\n",
       " ('The', 'DT'),\n",
       " ('acting', 'NN'),\n",
       " ('is', 'VBZ'),\n",
       " ('good', 'JJ'),\n",
       " (',', ','),\n",
       " ('not', 'RB'),\n",
       " ('overly', 'RB'),\n",
       " ('dramatic', 'JJ'),\n",
       " ('like', 'IN'),\n",
       " ('many', 'JJ'),\n",
       " ('other', 'JJ'),\n",
       " ('ww2', 'JJ'),\n",
       " ('films', 'NNS'),\n",
       " ('that', 'WDT'),\n",
       " ('have', 'VBP'),\n",
       " ('been', 'VBN'),\n",
       " ('made', 'VBN'),\n",
       " ('.', '.')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.pos_tag(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Case study - Replace words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word dictionary for BERT\n",
    "word_dict = []\n",
    "with open(\"bert-base-uncased-vocab.txt\", \"r\") as f:\n",
    "    for l in f.readlines():\n",
    "        word_dict.append(l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 10.00%.\n",
      "Finished 20.00%.\n",
      "Finished 30.00%.\n",
      "Finished 40.00%.\n",
      "Finished 50.00%.\n",
      "Finished 60.00%.\n",
      "Finished 70.00%.\n"
     ]
    }
   ],
   "source": [
    "# Brute force replace key words\n",
    "word_replace_MSE_dict = {}\n",
    "for i, w in enumerate(word_dict[999:], 1):\n",
    "    if i % int(len(word_dict[999:])/10) == 0:\n",
    "        print(\"Finished {:.2f}%.\".format(i / int(len(word_dict[999:])/10) * 10))\n",
    "    example_text_neg = example_text.replace(\"good\", w)#.replace(\"good\", \"good\")\n",
    "    with torch.no_grad():\n",
    "        example_tokenized_neg_untrained = tokenizer(example_text_neg, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "        example_origin_neg_cls_emb_untrained = model_untrained.base_model(**example_tokenized_neg_untrained)[0][0][0]\n",
    "        example_tokenized_untrained = tokenizer(example_text, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "        example_origin_cls_emb_untrained = model_untrained.base_model(**example_tokenized_untrained)[0][:,0,:]\n",
    "    word_replace_MSE_dict[w] = torch.norm(example_origin_neg_cls_emb_untrained - example_origin_cls_emb_untrained).item()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('good', 0.0),\n",
       " ('nice', 0.13435426354408264),\n",
       " ('great', 0.13668403029441833),\n",
       " ('well', 0.1559475213289261),\n",
       " ('fine', 0.16519874334335327),\n",
       " ('interesting', 0.17041532695293427),\n",
       " ('bad', 0.17150020599365234),\n",
       " ('best', 0.17429015040397644),\n",
       " ('wise', 0.17447488009929657),\n",
       " ('fast', 0.17616191506385803),\n",
       " ('excellent', 0.17644761502742767),\n",
       " ('kind', 0.17768529057502747),\n",
       " ('smart', 0.17798015475273132),\n",
       " ('strong', 0.17926186323165894),\n",
       " ('decent', 0.18114405870437622),\n",
       " ('serious', 0.18741022050380707),\n",
       " ('convincing', 0.18782706558704376),\n",
       " ('fair', 0.18830330669879913),\n",
       " ('clever', 0.18837271630764008),\n",
       " ('easy', 0.1899218112230301),\n",
       " ('hard', 0.18994919955730438),\n",
       " ('appealing', 0.18996204435825348),\n",
       " ('pretty', 0.19068105518817902),\n",
       " ('quality', 0.19214875996112823),\n",
       " ('fun', 0.1923743188381195),\n",
       " ('perfect', 0.1945510059595108),\n",
       " ('high', 0.1957029551267624),\n",
       " ('cool', 0.19599246978759766),\n",
       " ('quick', 0.19662681221961975),\n",
       " ('nicely', 0.1970011442899704),\n",
       " ('honest', 0.19803230464458466),\n",
       " ('comfortable', 0.1983153223991394),\n",
       " ('perfectly', 0.20047949254512787),\n",
       " ('charming', 0.20257516205310822),\n",
       " ('better', 0.20336636900901794),\n",
       " ('friendly', 0.20433339476585388),\n",
       " ('tough', 0.20629431307315826),\n",
       " ('exciting', 0.20741254091262817),\n",
       " ('ease', 0.20781736075878143),\n",
       " ('grand', 0.2078860104084015),\n",
       " ('sweet', 0.2082868367433548),\n",
       " ('fantastic', 0.20961476862430573),\n",
       " ('bright', 0.20968826115131378),\n",
       " ('clean', 0.2099909484386444),\n",
       " ('neat', 0.2103942632675171),\n",
       " ('much', 0.21124869585037231),\n",
       " ('big', 0.21151749789714813),\n",
       " ('brilliant', 0.212235227227211),\n",
       " ('sincere', 0.21303537487983704),\n",
       " ('fit', 0.2133106142282486),\n",
       " ('rich', 0.2137771099805832),\n",
       " ('ordinary', 0.21401643753051758),\n",
       " ('okay', 0.21408694982528687),\n",
       " ('careful', 0.21455448865890503),\n",
       " ('brave', 0.2158643752336502),\n",
       " ('economical', 0.21603433787822723),\n",
       " ('pure', 0.21643634140491486),\n",
       " ('badly', 0.21703074872493744),\n",
       " ('thorough', 0.21708907186985016),\n",
       " ('weak', 0.21750026941299438),\n",
       " ('shining', 0.21774651110172272),\n",
       " ('fresh', 0.2185535430908203),\n",
       " ('pleasing', 0.21892671287059784),\n",
       " ('terrible', 0.21909713745117188),\n",
       " ('intelligent', 0.2202349603176117),\n",
       " ('efficient', 0.22048552334308624),\n",
       " ('tight', 0.22055372595787048),\n",
       " ('reliable', 0.2208998054265976),\n",
       " ('amazing', 0.2209520936012268),\n",
       " ('thick', 0.2220917046070099),\n",
       " ('even', 0.22275935113430023),\n",
       " ('expert', 0.22278210520744324),\n",
       " ('average', 0.2228240668773651),\n",
       " ('amusing', 0.2228652685880661),\n",
       " ('competent', 0.2232711762189865),\n",
       " ('sense', 0.22345122694969177),\n",
       " ('innocent', 0.22353136539459229),\n",
       " ('mean', 0.22372718155384064),\n",
       " ('easily', 0.22383789718151093),\n",
       " ('solid', 0.2252649962902069),\n",
       " ('attractive', 0.22535865008831024),\n",
       " ('enough', 0.2254452258348465),\n",
       " ('obvious', 0.225447416305542),\n",
       " ('gross', 0.2255336195230484),\n",
       " ('loving', 0.2259141206741333),\n",
       " ('healthy', 0.22610345482826233),\n",
       " ('wonderful', 0.22645239531993866),\n",
       " ('powerful', 0.22680893540382385),\n",
       " ('heavy', 0.22689668834209442),\n",
       " ('capable', 0.2269534170627594),\n",
       " ('talented', 0.22698399424552917),\n",
       " ('style', 0.2273045927286148),\n",
       " ('just', 0.22763197124004364),\n",
       " ('natural', 0.22767950594425201),\n",
       " ('enjoyable', 0.22791409492492676),\n",
       " ('tired', 0.22816528379917145),\n",
       " ('fancy', 0.22905725240707397),\n",
       " ('plenty', 0.22933870553970337),\n",
       " ('professional', 0.23052878677845),\n",
       " ('thoroughly', 0.23053699731826782),\n",
       " ('funny', 0.23108318448066711),\n",
       " ('entertaining', 0.23146045207977295),\n",
       " ('intense', 0.23156218230724335),\n",
       " ('awful', 0.23160439729690552),\n",
       " ('total', 0.23234596848487854),\n",
       " ('normal', 0.23274190723896027),\n",
       " ('feel', 0.23335491120815277),\n",
       " ('beautifully', 0.23345112800598145),\n",
       " ('speedy', 0.23412995040416718),\n",
       " ('straight', 0.23433972895145416),\n",
       " ('handy', 0.23468001186847687),\n",
       " ('dumb', 0.2347419112920761),\n",
       " ('poor', 0.2348202019929886),\n",
       " ('genius', 0.2358807772397995),\n",
       " ('variety', 0.23594380915164948),\n",
       " ('abundant', 0.2369927018880844),\n",
       " ('full', 0.2370636761188507),\n",
       " ('rash', 0.23710951209068298),\n",
       " ('extreme', 0.23731210827827454),\n",
       " ('hot', 0.2376972734928131),\n",
       " ('alike', 0.2379668802022934),\n",
       " ('thrilling', 0.2383376657962799),\n",
       " ('sore', 0.23852817714214325),\n",
       " ('light', 0.23870955407619476),\n",
       " ('apt', 0.23886112868785858),\n",
       " ('anything', 0.23895864188671112),\n",
       " ('stupid', 0.23938873410224915),\n",
       " ('technical', 0.23944637179374695),\n",
       " ('sensitive', 0.23947694897651672),\n",
       " ('dramatic', 0.23969237506389618),\n",
       " ('elegant', 0.23969766497612),\n",
       " ('pleasant', 0.23980814218521118),\n",
       " ('speed', 0.23982049524784088),\n",
       " ('able', 0.23984232544898987),\n",
       " ('properly', 0.2398798167705536),\n",
       " ('care', 0.23997312784194946),\n",
       " ('extraordinary', 0.24020782113075256),\n",
       " ('general', 0.2402230054140091),\n",
       " ('tame', 0.2402510643005371),\n",
       " ('long', 0.24051937460899353),\n",
       " ('tender', 0.24090193212032318),\n",
       " ('skilled', 0.24106167256832123),\n",
       " ('valuable', 0.24126946926116943),\n",
       " ('fitting', 0.24149732291698456),\n",
       " ('noble', 0.24166721105575562),\n",
       " ('horrible', 0.24175214767456055),\n",
       " ('spectacular', 0.24181167781352997),\n",
       " ('fierce', 0.24185098707675934),\n",
       " ('sound', 0.2420833706855774),\n",
       " ('productive', 0.24218155443668365),\n",
       " ('successful', 0.2422417551279068),\n",
       " ('original', 0.24251021444797516),\n",
       " ('ideal', 0.24252289533615112),\n",
       " ('special', 0.24312426149845123),\n",
       " ('gorgeous', 0.24318882822990417),\n",
       " ('simple', 0.24327771365642548),\n",
       " ('genuine', 0.24331034719944),\n",
       " ('safe', 0.24346278607845306),\n",
       " ('realistic', 0.24380910396575928),\n",
       " ('wild', 0.24392561614513397),\n",
       " ('ample', 0.2439761459827423),\n",
       " ('sharp', 0.2440229058265686),\n",
       " ('work', 0.24437187612056732),\n",
       " ('cunning', 0.2445487380027771),\n",
       " ('tremendous', 0.24461475014686584),\n",
       " ('satisfying', 0.24462252855300903),\n",
       " ('shiny', 0.24491086602210999),\n",
       " ('soft', 0.24509267508983612),\n",
       " ('helpful', 0.2457517683506012),\n",
       " ('quickly', 0.24576160311698914),\n",
       " ('proper', 0.24585208296775818),\n",
       " ('lean', 0.24594935774803162),\n",
       " ('half', 0.2462180256843567),\n",
       " ('rapid', 0.2462548315525055),\n",
       " ('done', 0.2463350147008896),\n",
       " ('many', 0.24670648574829102),\n",
       " ('experienced', 0.24691566824913025),\n",
       " ('satisfactory', 0.24693916738033295),\n",
       " ('cute', 0.2471497356891632),\n",
       " ('terrific', 0.24729064106941223),\n",
       " ('slick', 0.2476215660572052),\n",
       " ('overwhelming', 0.24767723679542542),\n",
       " ('incredible', 0.2477884292602539),\n",
       " ('carefully', 0.24784976243972778),\n",
       " ('precious', 0.24836890399456024),\n",
       " ('harmless', 0.2486453503370285),\n",
       " ('warm', 0.24865885078907013),\n",
       " ('huge', 0.24878019094467163),\n",
       " ('adorable', 0.2487877905368805),\n",
       " ('delicious', 0.24932271242141724),\n",
       " ('highly', 0.24937355518341064),\n",
       " ('successfully', 0.24941661953926086),\n",
       " ('very', 0.24950170516967773),\n",
       " ('terribly', 0.24969376623630524),\n",
       " ('advanced', 0.2498522400856018),\n",
       " ('careless', 0.25020506978034973),\n",
       " ('handsome', 0.25021618604660034),\n",
       " ('complete', 0.25026145577430725),\n",
       " ('lovely', 0.25044888257980347),\n",
       " ('unbelievable', 0.2504805624485016),\n",
       " ('smooth', 0.2505529522895813),\n",
       " ('stable', 0.2506195306777954),\n",
       " ('daring', 0.2506497800350189),\n",
       " ('quicker', 0.2509552240371704),\n",
       " ('round', 0.2509715259075165),\n",
       " ('fat', 0.2510127127170563),\n",
       " ('familiar', 0.2512035369873047),\n",
       " ('stiff', 0.25145024061203003),\n",
       " ('fairly', 0.2518511116504669),\n",
       " ('exceptional', 0.25193092226982117),\n",
       " ('double', 0.251959890127182),\n",
       " ('nasty', 0.25199681520462036),\n",
       " ('plain', 0.252102255821228),\n",
       " ('sane', 0.2521318197250366),\n",
       " ('greatly', 0.25235339999198914),\n",
       " ('sham', 0.2525427043437958),\n",
       " ('skill', 0.25279247760772705),\n",
       " ('curious', 0.25329840183258057),\n",
       " ('severe', 0.25332745909690857),\n",
       " ('faithful', 0.25336742401123047),\n",
       " ('silly', 0.253695547580719),\n",
       " ('caring', 0.2537135183811188),\n",
       " ('noticeable', 0.25372931361198425),\n",
       " ('touching', 0.25375765562057495),\n",
       " ('lame', 0.2538285255432129),\n",
       " ('thin', 0.2543133795261383),\n",
       " ('little', 0.25481778383255005),\n",
       " ('imposing', 0.2548750340938568),\n",
       " ('rushed', 0.2548850476741791),\n",
       " ('generous', 0.25491225719451904),\n",
       " ('complex', 0.25498050451278687),\n",
       " ('demanding', 0.2553383409976959),\n",
       " ('spare', 0.2554278075695038),\n",
       " ('strength', 0.25551268458366394),\n",
       " ('irritating', 0.25552669167518616),\n",
       " ('such', 0.2555929124355316),\n",
       " ('sympathetic', 0.2557670474052429),\n",
       " ('small', 0.25629693269729614),\n",
       " ('cutting', 0.25629740953445435),\n",
       " ('made', 0.25636816024780273),\n",
       " ('reassuring', 0.25651660561561584),\n",
       " ('desperate', 0.2565717101097107),\n",
       " ('mess', 0.2565878927707672),\n",
       " ('slim', 0.2566363215446472),\n",
       " ('lax', 0.25664207339286804),\n",
       " ('agile', 0.25702139735221863),\n",
       " ('impressive', 0.25707247853279114),\n",
       " ('helped', 0.2570832669734955),\n",
       " ('whole', 0.2571663558483124),\n",
       " ('large', 0.25720810890197754),\n",
       " ('shock', 0.25727328658103943),\n",
       " ('spite', 0.2572905123233795),\n",
       " ('everything', 0.2573511600494385),\n",
       " ('gentle', 0.25756144523620605),\n",
       " ('bent', 0.25758954882621765),\n",
       " ('adequate', 0.2576991021633148),\n",
       " ('encouraging', 0.2578003406524658),\n",
       " ('content', 0.2578328549861908),\n",
       " ('perfection', 0.25788089632987976),\n",
       " ('practical', 0.2579136788845062),\n",
       " ('down', 0.25797805190086365),\n",
       " ('extra', 0.25806277990341187),\n",
       " ('faster', 0.25813499093055725),\n",
       " ('editing', 0.2581627070903778),\n",
       " ('effort', 0.25819429755210876),\n",
       " ('expensive', 0.25832173228263855),\n",
       " ('type', 0.25840744376182556),\n",
       " ('refreshing', 0.2585251033306122),\n",
       " ('frightening', 0.25856462121009827),\n",
       " ('dense', 0.2588599622249603),\n",
       " ('medical', 0.2588958442211151),\n",
       " ('ready', 0.25890350341796875),\n",
       " ('important', 0.25896796584129333),\n",
       " ('some', 0.2590315341949463),\n",
       " ('effective', 0.25932833552360535),\n",
       " ('bold', 0.25933751463890076),\n",
       " ('poorly', 0.2594712972640991),\n",
       " ('crazy', 0.2596019208431244),\n",
       " ('absolute', 0.25969618558883667),\n",
       " ('ill', 0.25981590151786804),\n",
       " ('stronger', 0.25988462567329407),\n",
       " ('massive', 0.25989338755607605),\n",
       " ('fool', 0.2599829435348511),\n",
       " ('flawless', 0.25999584794044495),\n",
       " ('really', 0.2600153088569641),\n",
       " ('lasting', 0.2600429058074951),\n",
       " ('worst', 0.2600952982902527),\n",
       " ('scenic', 0.2601228952407837),\n",
       " ('old', 0.2601688504219055),\n",
       " ('predictable', 0.26017865538597107),\n",
       " ('stubborn', 0.2601912319660187),\n",
       " ('worth', 0.26024535298347473),\n",
       " ('fascinating', 0.26035577058792114),\n",
       " ('medium', 0.2603627145290375),\n",
       " ('talent', 0.2605442702770233),\n",
       " ('odd', 0.2605581283569336),\n",
       " ('appreciated', 0.2605802118778229),\n",
       " ('energetic', 0.2606067359447479),\n",
       " ('heroic', 0.2606903910636902),\n",
       " ('firm', 0.2607787251472473),\n",
       " ('all', 0.2608792185783386),\n",
       " ('out', 0.26095953583717346),\n",
       " ('soothing', 0.2609672546386719),\n",
       " ('reasonable', 0.26097574830055237),\n",
       " ('polished', 0.26109281182289124),\n",
       " ('strongly', 0.2611045837402344),\n",
       " ('more', 0.2612195909023285),\n",
       " ('respectable', 0.26134413480758667),\n",
       " ('sure', 0.26175254583358765),\n",
       " ('typical', 0.26181840896606445),\n",
       " ('master', 0.26187050342559814),\n",
       " ('sake', 0.261963814496994),\n",
       " ('completely', 0.26199811697006226),\n",
       " ('action', 0.2621319890022278),\n",
       " ('naive', 0.2622082829475403),\n",
       " ('direction', 0.2623758018016815),\n",
       " ('spoiled', 0.26241543889045715),\n",
       " ('mostly', 0.2624652683734894),\n",
       " ('sophisticated', 0.2625315487384796),\n",
       " ('correctly', 0.2625398635864258),\n",
       " ('hardy', 0.26259973645210266),\n",
       " ('messy', 0.26270490884780884),\n",
       " ('luck', 0.2627953290939331),\n",
       " ('pity', 0.26299846172332764),\n",
       " ('positive', 0.2630898654460907),\n",
       " ('something', 0.2631218135356903),\n",
       " ('especially', 0.26341065764427185),\n",
       " ('understanding', 0.2637675404548645),\n",
       " ('motion', 0.2639808654785156),\n",
       " ('sensible', 0.2641371190547943),\n",
       " ('delicate', 0.2642015516757965),\n",
       " ('difficult', 0.26440104842185974),\n",
       " ('one', 0.2644284963607788),\n",
       " ('overly', 0.2646792531013489),\n",
       " ('honorable', 0.2648538053035736),\n",
       " ('mature', 0.2649279236793518),\n",
       " ('entertainment', 0.26493269205093384),\n",
       " ('objective', 0.26511040329933167),\n",
       " ('business', 0.26517292857170105),\n",
       " ('stellar', 0.2652873694896698),\n",
       " ('acted', 0.2655220627784729),\n",
       " ('slight', 0.265592485666275),\n",
       " ('balanced', 0.2656097710132599),\n",
       " ('too', 0.26566052436828613),\n",
       " ('confident', 0.26591959595680237),\n",
       " ('comprehensive', 0.26593369245529175),\n",
       " ('depth', 0.2659381926059723),\n",
       " ('mad', 0.2660231590270996),\n",
       " ('easiest', 0.2661416828632355),\n",
       " ('welcome', 0.266238808631897),\n",
       " ('cheap', 0.2664825916290283),\n",
       " ('elastic', 0.2665006220340729),\n",
       " ('immense', 0.26655200123786926),\n",
       " ('robust', 0.26678359508514404),\n",
       " ('loose', 0.2669372856616974),\n",
       " ('particular', 0.2671027183532715),\n",
       " ('lazy', 0.267191618680954),\n",
       " ('seasoned', 0.26744550466537476),\n",
       " ('racing', 0.26785770058631897),\n",
       " ('length', 0.2678828239440918),\n",
       " ('challenging', 0.26794496178627014),\n",
       " ('enthusiastic', 0.26795417070388794),\n",
       " ('superb', 0.26797497272491455),\n",
       " ('promising', 0.26801350712776184),\n",
       " ('whatever', 0.2680477797985077),\n",
       " ('exact', 0.2680607736110687),\n",
       " ('fluent', 0.26807066798210144),\n",
       " ('warmth', 0.2681276798248291),\n",
       " ('minute', 0.2681291699409485),\n",
       " ('gold', 0.26813122630119324),\n",
       " ('frail', 0.26823368668556213),\n",
       " ('comical', 0.2684757113456726),\n",
       " ('drastic', 0.2685573697090149),\n",
       " ('wit', 0.268749862909317),\n",
       " ('courageous', 0.2687853276729584),\n",
       " ('major', 0.26880770921707153),\n",
       " ('calculating', 0.2688191533088684),\n",
       " ('clumsy', 0.26894596219062805),\n",
       " ('proportional', 0.2689940631389618),\n",
       " ('sport', 0.26899853348731995),\n",
       " ('beautiful', 0.2691228985786438),\n",
       " ('oriented', 0.26919984817504883),\n",
       " ('few', 0.2692627012729645),\n",
       " ('simplicity', 0.26927781105041504),\n",
       " ('shaky', 0.26929447054862976),\n",
       " ('intensive', 0.2694697380065918),\n",
       " ('clear', 0.2694781422615051),\n",
       " ('heart', 0.2695004343986511),\n",
       " ('relief', 0.26981934905052185),\n",
       " ('sheer', 0.2698984444141388),\n",
       " ('logical', 0.2699587345123291),\n",
       " ('sentimental', 0.27003049850463867),\n",
       " ('specialized', 0.27013927698135376),\n",
       " ('sloppy', 0.270311564207077),\n",
       " ('civilized', 0.27035364508628845),\n",
       " ('dirty', 0.27039453387260437),\n",
       " ('arresting', 0.27048540115356445),\n",
       " ('wide', 0.2705082297325134),\n",
       " ('civil', 0.27051958441734314),\n",
       " ('lucky', 0.27056795358657837),\n",
       " ('heavily', 0.2706030607223511),\n",
       " ('strict', 0.2706218957901001),\n",
       " ('exactly', 0.27063119411468506),\n",
       " ('outstanding', 0.27064913511276245),\n",
       " ('barely', 0.2706950008869171),\n",
       " ('surprising', 0.2709738612174988),\n",
       " ('trouble', 0.27097782492637634),\n",
       " ('seriously', 0.27109357714653015),\n",
       " ('harsh', 0.2710963487625122),\n",
       " ('adept', 0.271170437335968),\n",
       " ('wicked', 0.271258682012558),\n",
       " ('less', 0.271283358335495),\n",
       " ('hardest', 0.2714296281337738),\n",
       " ('method', 0.27144142985343933),\n",
       " ('regular', 0.2714981436729431),\n",
       " ('valiant', 0.27154189348220825),\n",
       " ('efficiently', 0.2715998589992523),\n",
       " ('almost', 0.27162352204322815),\n",
       " ('superior', 0.2716546356678009),\n",
       " ('finer', 0.27165520191192627),\n",
       " ('totally', 0.27178552746772766),\n",
       " ('usual', 0.2718799412250519),\n",
       " ('any', 0.2720243036746979),\n",
       " ('passionate', 0.2721855938434601),\n",
       " ('suspicious', 0.27230316400527954),\n",
       " ('scientific', 0.2724918723106384),\n",
       " ('science', 0.27256476879119873),\n",
       " ('constructive', 0.2725822329521179),\n",
       " ('pop', 0.27269354462623596),\n",
       " ('crisp', 0.27271682024002075),\n",
       " ('stuff', 0.27294406294822693),\n",
       " ('professionally', 0.2729807496070862),\n",
       " ('crushing', 0.2730129063129425),\n",
       " ('suited', 0.27303966879844666),\n",
       " ('kindly', 0.2730478346347809),\n",
       " ('stimulating', 0.27309876680374146),\n",
       " ('durable', 0.273110955953598),\n",
       " ('meek', 0.2731863856315613),\n",
       " ('extremely', 0.27330660820007324),\n",
       " ('up', 0.2733204960823059),\n",
       " ('draw', 0.2733229994773865),\n",
       " ('exquisite', 0.2733483612537384),\n",
       " ('grave', 0.27335092425346375),\n",
       " ('worrying', 0.27337920665740967),\n",
       " ('vain', 0.2734639346599579),\n",
       " ('lively', 0.2735176384449005),\n",
       " ('biting', 0.2736147344112396),\n",
       " ('deep', 0.2736470103263855),\n",
       " ('adventure', 0.2737888693809509),\n",
       " ('grit', 0.2738334834575653),\n",
       " ('smoothly', 0.2739928066730499),\n",
       " ('credible', 0.27403688430786133),\n",
       " ('adventurous', 0.27415192127227783),\n",
       " ('realism', 0.27422651648521423),\n",
       " ('fault', 0.2742723822593689),\n",
       " ('young', 0.274315744638443),\n",
       " ('absorbing', 0.2743285000324249),\n",
       " ('still', 0.2743723690509796),\n",
       " ('shallow', 0.2747074365615845),\n",
       " ('complicated', 0.27476534247398376),\n",
       " ('moral', 0.2748047113418579),\n",
       " ('damaging', 0.27486559748649597),\n",
       " ('easier', 0.2750481367111206),\n",
       " ('zero', 0.2750687599182129),\n",
       " ('favorable', 0.27507779002189636),\n",
       " ('steady', 0.2750931978225708),\n",
       " ('basic', 0.27511146664619446),\n",
       " ('voice', 0.2752341032028198),\n",
       " ('wrong', 0.27533388137817383),\n",
       " ('slightly', 0.27534887194633484),\n",
       " ('foreign', 0.2753773033618927),\n",
       " ('goodness', 0.2754167318344116),\n",
       " ('wonder', 0.27547183632850647),\n",
       " ('fearless', 0.27551567554473877),\n",
       " ('urgent', 0.27553659677505493),\n",
       " ('keen', 0.2756069004535675),\n",
       " ('dry', 0.27565625309944153),\n",
       " ('trick', 0.275663822889328),\n",
       " ('brisk', 0.2756893038749695),\n",
       " ('matter', 0.27574974298477173),\n",
       " ('auto', 0.27576127648353577),\n",
       " ('determined', 0.27581092715263367),\n",
       " ('sick', 0.27581822872161865),\n",
       " ('hurry', 0.2759440243244171),\n",
       " ('material', 0.2759978473186493),\n",
       " ('slow', 0.27602630853652954),\n",
       " ('trusting', 0.27604106068611145),\n",
       " ('witty', 0.2760457694530487),\n",
       " ('elaborate', 0.2760484218597412),\n",
       " ('stressed', 0.27614739537239075),\n",
       " ('nothing', 0.2761591970920563),\n",
       " ('thoughtful', 0.2761651873588562),\n",
       " ('moderate', 0.2761841416358948),\n",
       " ('striking', 0.2762093245983124),\n",
       " ('rounded', 0.2762204706668854),\n",
       " ('comforting', 0.27632376551628113),\n",
       " ('superficial', 0.27637213468551636),\n",
       " ('patience', 0.27639079093933105),\n",
       " ('otherwise', 0.2763945162296295),\n",
       " ('somehow', 0.2764931619167328),\n",
       " ('subtle', 0.2765391170978546),\n",
       " ('lots', 0.27669474482536316),\n",
       " ('rush', 0.27674320340156555),\n",
       " ('useful', 0.2768774628639221),\n",
       " ('sparkling', 0.2769453823566437),\n",
       " ('intimidating', 0.2769697308540344),\n",
       " ('partial', 0.27697473764419556),\n",
       " ('mild', 0.27710452675819397),\n",
       " ('enormous', 0.2771191895008087),\n",
       " ('avid', 0.27714309096336365),\n",
       " ('colossal', 0.27714866399765015),\n",
       " ('mighty', 0.27716296911239624),\n",
       " ('ferocious', 0.27721109986305237),\n",
       " ('micro', 0.27724286913871765),\n",
       " ('enjoy', 0.2772606611251831),\n",
       " ('creative', 0.277265727519989),\n",
       " ('difficulty', 0.27742382884025574),\n",
       " ('true', 0.27745166420936584),\n",
       " ('risky', 0.27745532989501953),\n",
       " ('graceful', 0.27750125527381897),\n",
       " ('level', 0.2775115370750427),\n",
       " ('trivial', 0.27751624584198),\n",
       " ('grim', 0.27753010392189026),\n",
       " ('pitch', 0.27753353118896484),\n",
       " ('excessive', 0.2776198089122772),\n",
       " ('rational', 0.2776511311531067),\n",
       " ('stress', 0.27766695618629456),\n",
       " ('controlling', 0.2776705026626587),\n",
       " ('modest', 0.2777184247970581),\n",
       " ('precision', 0.2778453528881073),\n",
       " ('short', 0.2779688239097595),\n",
       " ('dangerous', 0.2779735326766968),\n",
       " ('neatly', 0.27808377146720886),\n",
       " ('crap', 0.278389573097229),\n",
       " ('off', 0.2784152030944824),\n",
       " ('happy', 0.2786295711994171),\n",
       " ('sort', 0.2787058353424072),\n",
       " ('memorable', 0.27871254086494446),\n",
       " ('strongest', 0.27875855565071106),\n",
       " ('real', 0.27879559993743896),\n",
       " ('chance', 0.27885574102401733),\n",
       " ('fully', 0.2788902223110199),\n",
       " ('deadly', 0.2788931131362915),\n",
       " ('beauty', 0.2789524495601654),\n",
       " ('universal', 0.27901026606559753),\n",
       " ('show', 0.27910348773002625),\n",
       " ('apologetic', 0.2791459560394287),\n",
       " ('potent', 0.2792566418647766),\n",
       " ('affecting', 0.2793203890323639),\n",
       " ('greatest', 0.2793692350387573),\n",
       " ('stunning', 0.2793855667114258),\n",
       " ('glorious', 0.279440701007843),\n",
       " ('modern', 0.279487282037735),\n",
       " ('close', 0.27949386835098267),\n",
       " ('willing', 0.2795501947402954),\n",
       " ('uncomfortable', 0.27956879138946533),\n",
       " ('self', 0.2796724736690521),\n",
       " ('considerably', 0.2797396183013916),\n",
       " ('specific', 0.2797533869743347),\n",
       " ('tiny', 0.27979061007499695),\n",
       " ('convenient', 0.27982863783836365),\n",
       " ('so', 0.27988675236701965),\n",
       " ('worry', 0.2799377739429474),\n",
       " ('swell', 0.279952734708786),\n",
       " ('count', 0.2800017297267914),\n",
       " ('professionals', 0.280102014541626),\n",
       " ('elementary', 0.28013867139816284),\n",
       " ('makeup', 0.2802267372608185),\n",
       " ('extensive', 0.2802976369857788),\n",
       " ('somewhat', 0.28029772639274597),\n",
       " ('definite', 0.28037336468696594),\n",
       " ('relaxed', 0.2805916368961334),\n",
       " ('humane', 0.28061071038246155),\n",
       " ('accomplished', 0.28065311908721924),\n",
       " ('field', 0.28076595067977905),\n",
       " ('concentrated', 0.28085675835609436),\n",
       " ('touch', 0.28099942207336426),\n",
       " ('theatrical', 0.2810465097427368),\n",
       " ('arrogant', 0.28111356496810913),\n",
       " ('definitely', 0.28115734457969666),\n",
       " ('pathetic', 0.2811881899833679),\n",
       " ('boring', 0.28119292855262756),\n",
       " ('simply', 0.28125977516174316),\n",
       " ('chemistry', 0.2813097834587097),\n",
       " ('rosy', 0.2813136577606201),\n",
       " ('justified', 0.2814396321773529),\n",
       " ('timely', 0.2815113067626953),\n",
       " ('reasonably', 0.2817409038543701),\n",
       " ('flair', 0.281775563955307),\n",
       " ('fantasy', 0.28181442618370056),\n",
       " ('tightly', 0.2819209098815918),\n",
       " ('systematic', 0.2820204794406891),\n",
       " ('most', 0.2820419669151306),\n",
       " ('rough', 0.28204870223999023),\n",
       " ('taste', 0.2820792496204376),\n",
       " ('immaculate', 0.2821148931980133),\n",
       " ('lighting', 0.2821897864341736),\n",
       " ('fragile', 0.28222280740737915),\n",
       " ('costly', 0.2822347581386566),\n",
       " ('hope', 0.2823237180709839),\n",
       " ('id', 0.28237244486808777),\n",
       " ('painfully', 0.28255918622016907),\n",
       " ('sufficient', 0.28262147307395935),\n",
       " ('refined', 0.28265678882598877),\n",
       " ('eager', 0.28271663188934326),\n",
       " ('lack', 0.28278791904449463),\n",
       " ('dialogue', 0.2828022241592407),\n",
       " ('every', 0.2828463613986969),\n",
       " ('hasty', 0.282880961894989),\n",
       " ('there', 0.2829256057739258),\n",
       " ('mere', 0.28292810916900635),\n",
       " ('super', 0.2829281687736511),\n",
       " ('raw', 0.28301382064819336),\n",
       " ('numerous', 0.28301575779914856),\n",
       " ('wasted', 0.2830258905887604),\n",
       " ('flash', 0.2830277979373932),\n",
       " ('pen', 0.28304001688957214),\n",
       " ('negative', 0.28315040469169617),\n",
       " ('tricks', 0.2832097113132477),\n",
       " ('sweaty', 0.28324246406555176),\n",
       " ('key', 0.283243864774704),\n",
       " ('closely', 0.28333473205566406),\n",
       " ('gripping', 0.2833736538887024),\n",
       " ('do', 0.28338971734046936),\n",
       " ('minor', 0.2835386395454407),\n",
       " ('blazing', 0.28356510400772095),\n",
       " ('idiot', 0.2835940420627594),\n",
       " ('psychological', 0.2836467921733856),\n",
       " ('ink', 0.28366994857788086),\n",
       " ('error', 0.2836865484714508),\n",
       " ('foolish', 0.2837037742137909),\n",
       " ('lead', 0.2837463617324829),\n",
       " ('elevated', 0.28377261757850647),\n",
       " ('pulp', 0.28400543332099915),\n",
       " ('corrupt', 0.28408223390579224),\n",
       " ('sticky', 0.2841671109199524),\n",
       " ('authentic', 0.2843153178691864),\n",
       " ('direct', 0.28450340032577515),\n",
       " ('experience', 0.28452634811401367),\n",
       " ('uniform', 0.28454381227493286),\n",
       " ('deeply', 0.284557580947876),\n",
       " ('jerk', 0.2846401035785675),\n",
       " ('dull', 0.28472477197647095),\n",
       " ('rugged', 0.2848643958568573),\n",
       " ('benign', 0.2848886549472809),\n",
       " ('naturally', 0.28495240211486816),\n",
       " ('stock', 0.28495460748672485),\n",
       " ('order', 0.28497031331062317),\n",
       " ('powered', 0.28501561284065247),\n",
       " ('pleasure', 0.28502151370048523),\n",
       " ('vast', 0.28512877225875854),\n",
       " ('kindness', 0.2851872742176056),\n",
       " ('love', 0.28525781631469727),\n",
       " ('greedy', 0.2852970361709595),\n",
       " ('healing', 0.2853046655654907),\n",
       " ('beat', 0.28532326221466064),\n",
       " ('prolific', 0.28539565205574036),\n",
       " ('evenly', 0.28546687960624695),\n",
       " ('make', 0.285486102104187),\n",
       " ('max', 0.2855132818222046),\n",
       " ('ragged', 0.28552278876304626),\n",
       " ('compact', 0.2855684459209442),\n",
       " ('pain', 0.2857415974140167),\n",
       " ('suitable', 0.2858237624168396),\n",
       " ('lavish', 0.2858327329158783),\n",
       " ('longer', 0.28583431243896484),\n",
       " ('square', 0.2858394980430603),\n",
       " ('low', 0.2859025299549103),\n",
       " ('power', 0.28592649102211),\n",
       " ('genuinely', 0.2859697937965393),\n",
       " ('extravagant', 0.2859874367713928),\n",
       " ('absolutely', 0.28602150082588196),\n",
       " ('right', 0.28604862093925476),\n",
       " ('respected', 0.2861258387565613),\n",
       " ('sturdy', 0.2861371338367462),\n",
       " ('versatile', 0.28617429733276367),\n",
       " ('rocky', 0.2862035632133484),\n",
       " ('worked', 0.2862085700035095),\n",
       " ('hurried', 0.2862324118614197),\n",
       " ('secure', 0.28625205159187317),\n",
       " ('rapidly', 0.2862749695777893),\n",
       " ('incredibly', 0.28646111488342285),\n",
       " ('else', 0.2864896357059479),\n",
       " ('altogether', 0.2865488827228546),\n",
       " ('blinding', 0.28655382990837097),\n",
       " ('dependent', 0.2866080701351166),\n",
       " ('delightful', 0.2866242825984955),\n",
       " ('scratch', 0.286679744720459),\n",
       " ('numb', 0.28688082098960876),\n",
       " ('dynamic', 0.28688836097717285),\n",
       " ('astronomical', 0.2868902385234833),\n",
       " ('weaker', 0.2869129478931427),\n",
       " ('accustomed', 0.28700631856918335),\n",
       " ('reactive', 0.28708314895629883),\n",
       " ('lightly', 0.2870941758155823),\n",
       " ('limited', 0.287158340215683),\n",
       " ('language', 0.2872623801231384),\n",
       " ('rude', 0.2873026132583618),\n",
       " ('painful', 0.28747060894966125),\n",
       " ('breath', 0.2875406742095947),\n",
       " ('trained', 0.28756317496299744),\n",
       " ('pounding', 0.28756585717201233),\n",
       " ('supporting', 0.2875816524028778),\n",
       " ('tempting', 0.2876286804676056),\n",
       " ('scare', 0.28766652941703796),\n",
       " ('dark', 0.2877023220062256),\n",
       " ('polite', 0.28776928782463074),\n",
       " ('manual', 0.28781336545944214),\n",
       " ('martial', 0.287849098443985),\n",
       " ('pad', 0.28787875175476074),\n",
       " ('loss', 0.28793394565582275),\n",
       " ('need', 0.28805413842201233),\n",
       " ('relax', 0.2880576550960541),\n",
       " ('prepared', 0.2882544696331024),\n",
       " ('comic', 0.2882654368877411),\n",
       " ('peaceful', 0.28827574849128723),\n",
       " ('forced', 0.2883903980255127),\n",
       " ('no', 0.2884095013141632),\n",
       " ('mass', 0.28847476840019226),\n",
       " ('generalized', 0.2885024845600128),\n",
       " ('honestly', 0.2885761260986328),\n",
       " ('determination', 0.28857794404029846),\n",
       " ('active', 0.2886260449886322),\n",
       " ('surprisingly', 0.28867459297180176),\n",
       " ('lush', 0.28871774673461914),\n",
       " ('cautious', 0.2887899875640869),\n",
       " ('useless', 0.2888004183769226),\n",
       " ('calculated', 0.288845419883728),\n",
       " ('pretend', 0.2888981103897095),\n",
       " ('inclined', 0.28890010714530945),\n",
       " ('marvelous', 0.28890368342399597),\n",
       " ('intriguing', 0.28900259733200073),\n",
       " ('ray', 0.2890315353870392),\n",
       " ('pointed', 0.28908947110176086),\n",
       " ('magic', 0.289230614900589),\n",
       " ('sly', 0.2892470061779022),\n",
       " ('gently', 0.28930580615997314),\n",
       " ('equal', 0.2893429100513458),\n",
       " ('flat', 0.28934410214424133),\n",
       " ('string', 0.28947576880455017),\n",
       " ('sunny', 0.28947851061820984),\n",
       " ('mastered', 0.2894929349422455),\n",
       " ('anti', 0.2895757853984833),\n",
       " ('miraculous', 0.2896135449409485),\n",
       " ('annoying', 0.2896212339401245),\n",
       " ('anyway', 0.2896435260772705),\n",
       " ('desperately', 0.2896488606929779),\n",
       " ('acid', 0.2897235155105591),\n",
       " ('entirely', 0.2897525727748871),\n",
       " ('flawed', 0.2897820472717285),\n",
       " ('saturated', 0.2897907793521881),\n",
       " ('take', 0.2898498773574829),\n",
       " ('act', 0.2898615300655365),\n",
       " ('truly', 0.2898746132850647),\n",
       " ('romantic', 0.28989529609680176),\n",
       " ('force', 0.2899254858493805),\n",
       " ('innovative', 0.28996139764785767),\n",
       " ('earnest', 0.2899879813194275),\n",
       " ('inexperienced', 0.28999489545822144),\n",
       " ('prime', 0.2900235056877136),\n",
       " ('shocking', 0.2902461588382721),\n",
       " ('fuzzy', 0.2902931869029999),\n",
       " ('harder', 0.290355384349823),\n",
       " ('rather', 0.29048237204551697),\n",
       " ('evil', 0.29051947593688965),\n",
       " ('free', 0.2905309200286865),\n",
       " ('assisted', 0.2905958294868469),\n",
       " ('salty', 0.2907421886920929),\n",
       " ('sweeping', 0.2908898591995239),\n",
       " ('loud', 0.2909322679042816),\n",
       " ('accident', 0.29094353318214417),\n",
       " ('sympathy', 0.2909736931324005),\n",
       " ('clearly', 0.29108530282974243),\n",
       " ('cold', 0.2911834418773651),\n",
       " ('selective', 0.29120469093322754),\n",
       " ('joy', 0.2912556827068329),\n",
       " ('infectious', 0.2913455665111542),\n",
       " ('smarter', 0.2913943827152252),\n",
       " ('courage', 0.2914580702781677),\n",
       " ('boxing', 0.2914775609970093),\n",
       " ('fuss', 0.29149240255355835),\n",
       " ('forensic', 0.291520893573761),\n",
       " ('comfort', 0.2915351688861847),\n",
       " ('hyper', 0.29163387417793274),\n",
       " ('dazzling', 0.2916644215583801),\n",
       " ('sorry', 0.2916807532310486),\n",
       " ('psycho', 0.2916862666606903),\n",
       " ('conditioned', 0.2916923761367798),\n",
       " ('embarrassing', 0.29170534014701843),\n",
       " ('appeal', 0.29172393679618835),\n",
       " ('homemade', 0.29173922538757324),\n",
       " ('late', 0.29175105690956116),\n",
       " ('clinical', 0.29175662994384766),\n",
       " ('brittle', 0.2917596399784088),\n",
       " ('worthy', 0.2918088436126709),\n",
       " ('broken', 0.29193344712257385),\n",
       " ('strange', 0.29199719429016113),\n",
       " ('fashioned', 0.2920466959476471),\n",
       " ('heat', 0.2920600473880768),\n",
       " ('fright', 0.29213428497314453),\n",
       " ('horribly', 0.29226022958755493),\n",
       " ('managed', 0.29229965806007385),\n",
       " ('mental', 0.29231488704681396),\n",
       " ('remarkable', 0.2923717796802521),\n",
       " ('explosive', 0.2924697697162628),\n",
       " ('childish', 0.292631596326828),\n",
       " ('textbook', 0.2927752137184143),\n",
       " ('fire', 0.29277756810188293),\n",
       " ('awkward', 0.2927808463573456),\n",
       " ('sets', 0.29280200600624084),\n",
       " ('push', 0.29290735721588135),\n",
       " ('devastating', 0.2929178774356842),\n",
       " ('tentative', 0.29291942715644836),\n",
       " ('precisely', 0.2929309606552124),\n",
       " ('ambitious', 0.2929944396018982),\n",
       " ('bald', 0.29307809472084045),\n",
       " ('scoring', 0.2930845022201538),\n",
       " ('felt', 0.2931075096130371),\n",
       " ('skills', 0.29314666986465454),\n",
       " ('startling', 0.2931940257549286),\n",
       " ('geared', 0.29321882128715515),\n",
       " ('adjusted', 0.2932881712913513),\n",
       " ('obviously', 0.29336559772491455),\n",
       " ('insignificant', 0.29337453842163086),\n",
       " ('fastest', 0.2934367060661316),\n",
       " ('mini', 0.29351168870925903),\n",
       " ('purpose', 0.29362550377845764),\n",
       " ('confusing', 0.2936321496963501),\n",
       " ('engineering', 0.29366055130958557),\n",
       " ('therapeutic', 0.29371947050094604),\n",
       " ('facial', 0.2937251925468445),\n",
       " ('inviting', 0.2938235104084015),\n",
       " ('muscular', 0.29384055733680725),\n",
       " ('scary', 0.293948233127594),\n",
       " ('fixed', 0.2939934730529785),\n",
       " ('dust', 0.2940038740634918),\n",
       " ('con', 0.2940053939819336),\n",
       " ('packed', 0.2941147983074188),\n",
       " ('brute', 0.29413625597953796),\n",
       " ('accurately', 0.29415836930274963),\n",
       " ('broad', 0.29416048526763916),\n",
       " ('decoration', 0.29423990845680237),\n",
       " ('immature', 0.29431742429733276),\n",
       " ('respectful', 0.2944316864013672),\n",
       " ('poison', 0.29444199800491333),\n",
       " ('loco', 0.2944905161857605),\n",
       " ('bravery', 0.294533371925354),\n",
       " ('giant', 0.29466119408607483),\n",
       " ('amazingly', 0.2946707606315613),\n",
       " ('industrial', 0.294672429561615),\n",
       " ('engaging', 0.29470229148864746),\n",
       " ('talk', 0.294769823551178),\n",
       " ('mach', 0.2947786748409271),\n",
       " ('emotional', 0.29482918977737427),\n",
       " ('un', 0.29485687613487244),\n",
       " ('save', 0.2948589622974396),\n",
       " ('characteristic', 0.29487860202789307),\n",
       " ('particularly', 0.29489025473594666),\n",
       " ('pot', 0.2949780821800232),\n",
       " ('prominent', 0.2950551509857178),\n",
       " ('spontaneous', 0.2950561046600342),\n",
       " ('salt', 0.2950661778450012),\n",
       " ('po', 0.29517805576324463),\n",
       " ('verve', 0.2951849102973938),\n",
       " ('vigorous', 0.29519903659820557),\n",
       " ('worse', 0.2952403128147125),\n",
       " ('types', 0.2953096032142639),\n",
       " ('weird', 0.29532548785209656),\n",
       " ('suspense', 0.2953628897666931),\n",
       " ('shadow', 0.2954448163509369),\n",
       " ('thermal', 0.2954590916633606),\n",
       " ('pacing', 0.2954649031162262),\n",
       " ('standard', 0.2955445945262909),\n",
       " ('severely', 0.2955583930015564),\n",
       " ('dire', 0.29556041955947876),\n",
       " ('paper', 0.2955764830112457),\n",
       " ('advice', 0.29558688402175903),\n",
       " ('age', 0.2956107258796692),\n",
       " ('haste', 0.29577872157096863),\n",
       " ('diagnostic', 0.2958277761936188),\n",
       " ('gore', 0.2959374189376831),\n",
       " ('flesh', 0.29593798518180847),\n",
       " ('luxurious', 0.295976459980011),\n",
       " ('rampant', 0.29603105783462524),\n",
       " ('creativity', 0.2960646450519562),\n",
       " ('familiarity', 0.2960854768753052),\n",
       " ('swift', 0.296120285987854),\n",
       " ('lie', 0.2962091565132141),\n",
       " ('pumped', 0.29623886942863464),\n",
       " ('slowly', 0.29625818133354187),\n",
       " ('code', 0.29630622267723083),\n",
       " ('shape', 0.2963399589061737),\n",
       " ('safely', 0.2964126467704773),\n",
       " ('fatigue', 0.2964262366294861),\n",
       " ('accurate', 0.29642942547798157),\n",
       " ('human', 0.29643070697784424),\n",
       " ('sparkle', 0.2965376377105713),\n",
       " ('physics', 0.2965666353702545),\n",
       " ('liquid', 0.2965705990791321),\n",
       " ('positively', 0.29657286405563354),\n",
       " ('adrenaline', 0.29658201336860657),\n",
       " ('classical', 0.2966673970222473),\n",
       " ('animal', 0.2966681718826294),\n",
       " ('bulky', 0.2966715097427368),\n",
       " ('aimed', 0.29669737815856934),\n",
       " ('blood', 0.2967233657836914),\n",
       " ('mischief', 0.29675430059432983),\n",
       " ('canon', 0.2968359887599945),\n",
       " ('firmly', 0.29690518975257874),\n",
       " ('destructive', 0.2969379127025604),\n",
       " ('tuned', 0.2969633936882019),\n",
       " ('calm', 0.2969783544540405),\n",
       " ('brush', 0.297001451253891),\n",
       " ('disciplined', 0.29701241850852966),\n",
       " ('sage', 0.29714033007621765),\n",
       " ('richer', 0.29717281460762024),\n",
       " ('g', 0.29718759655952454),\n",
       " ('relaxing', 0.2972804605960846),\n",
       " ('comfortably', 0.29736265540122986),\n",
       " ('youthful', 0.297379732131958),\n",
       " ('powder', 0.2973858118057251),\n",
       " ('pumping', 0.29740387201309204),\n",
       " ('inflated', 0.29747676849365234),\n",
       " ('jagged', 0.2974861264228821),\n",
       " ('straightforward', 0.2975574731826782),\n",
       " ('inexpensive', 0.29756221175193787),\n",
       " ('nearly', 0.2975820004940033),\n",
       " ('phantom', 0.29760485887527466),\n",
       " ('aching', 0.2976168692111969),\n",
       " ('vital', 0.2976410686969757),\n",
       " ('chilling', 0.2976745665073395),\n",
       " ('arts', 0.2976910173892975),\n",
       " ('preparation', 0.2977297306060791),\n",
       " ('various', 0.2977369427680969),\n",
       " ('honesty', 0.2978155314922333),\n",
       " ('pro', 0.29781776666641235),\n",
       " ('appropriate', 0.29783737659454346),\n",
       " ('loaded', 0.2978421747684479),\n",
       " ('authoritative', 0.29786112904548645),\n",
       " ('wet', 0.29787206649780273),\n",
       " ('acute', 0.2979288399219513),\n",
       " ('mistakes', 0.29799339175224304),\n",
       " ('browning', 0.2979949116706848),\n",
       " ('spirited', 0.2980199158191681),\n",
       " ('thumping', 0.29802724719047546),\n",
       " ('tempered', 0.29806944727897644),\n",
       " ('hardened', 0.2981451451778412),\n",
       " ('lighter', 0.29816386103630066),\n",
       " ('canned', 0.2982238531112671),\n",
       " ('eye', 0.2982269823551178),\n",
       " ('sped', 0.2982301712036133),\n",
       " ('nonsense', 0.29830485582351685),\n",
       " ('higher', 0.2983361482620239),\n",
       " ('blind', 0.2983579635620117),\n",
       " ('progressive', 0.29836562275886536),\n",
       " ('heavier', 0.2983771860599518),\n",
       " ('classic', 0.29837900400161743),\n",
       " ('suit', 0.2983818054199219),\n",
       " ('ed', 0.29841750860214233),\n",
       " ('math', 0.2984348237514496),\n",
       " ('studio', 0.2984358072280884),\n",
       " ('righteous', 0.298475056886673),\n",
       " ('knowledge', 0.2984863221645355),\n",
       " ('conscious', 0.2985018491744995),\n",
       " ('orderly', 0.2985563278198242),\n",
       " ('athletic', 0.29859182238578796),\n",
       " ('tailored', 0.29861560463905334),\n",
       " ('normally', 0.2987145185470581),\n",
       " ('excitement', 0.29872801899909973),\n",
       " ('frantic', 0.2987912595272064),\n",
       " ('freak', 0.2987971901893616),\n",
       " ('shy', 0.298809677362442),\n",
       " ('immediate', 0.2988317310810089),\n",
       " ('sting', 0.29884621500968933),\n",
       " ('sweat', 0.298864483833313),\n",
       " ('focused', 0.2988928556442261),\n",
       " ('air', 0.2989289164543152),\n",
       " ('softened', 0.29893288016319275),\n",
       " ('tricky', 0.29894861578941345),\n",
       " ('accidental', 0.2989635467529297),\n",
       " ('strictly', 0.2989726662635803),\n",
       " ('excess', 0.29898056387901306),\n",
       " ('assured', 0.298996239900589),\n",
       " ('tidy', 0.29900816082954407),\n",
       " ('patient', 0.29902756214141846),\n",
       " ('techniques', 0.2990370988845825),\n",
       " ('radiant', 0.29907259345054626),\n",
       " ('weight', 0.2990797460079193),\n",
       " ('driven', 0.29909342527389526),\n",
       " ('pressing', 0.2991006076335907),\n",
       " ('directed', 0.29915037751197815),\n",
       " ('dominating', 0.29922205209732056),\n",
       " ('finely', 0.29924651980400085),\n",
       " ('shed', 0.29925301671028137),\n",
       " ('directional', 0.2992863059043884),\n",
       " ('point', 0.2993222773075104),\n",
       " ('calculation', 0.2993841767311096),\n",
       " ('brightly', 0.29943346977233887),\n",
       " ('insane', 0.29946190118789673),\n",
       " ('guide', 0.29953452944755554),\n",
       " ...]"
      ]
     },
     "execution_count": 332,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(list(word_replace_MSE_dict.items()), key=lambda x:x[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_text_neg = example_text.replace(\"good\", \"bad\")#.replace(\"good\", \"good\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    example_tokenized_neg = tokenizer(example_text_neg, truncation=True, padding=True, return_tensors='pt').to(device)\n",
    "    example_origin_neg_cls_emb = model.base_model(**example_tokenized_neg)[0][0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.4837, device='cuda:0')"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(example_origin_neg_cls_emb - example_origin_cls_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.4073, -0.2153], device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 336,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier(example_origin_neg_cls_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4173, -0.2270]], device='cuda:0', grad_fn=<AddmmBackward>)"
      ]
     },
     "execution_count": 273,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.classifier(example_origin_cls_emb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Antonym - NLTK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import nltk\n",
    "# nltk.download('wordnet')\n",
    "# from nltk.corpus import wordnet as wn\n",
    "\n",
    "# stop_words = get_stopwords()\n",
    "# word_id_dict = pickle.load(open(\"word_id_dict.pkl\", \"rb\"))\n",
    "# id_word_dict = pickle.load(open(\"id_word_dict.pkl\", \"rb\"))\n",
    "# word_sim_embeddings = np.load(\"word_sim_embeddings.npy\")\n",
    "\n",
    "# greats = wn.synsets(\"up\")\n",
    "# [great_lemma.antonyms() for great_lemmas in [great.lemmas() for great in greats] for great_lemma in great_lemmas if great_lemma.antonyms()!=[]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NOT WORKING: SIMILARITY only works for synonym\n",
    "# tokenid_perturb = np.array([135])\n",
    "# word2replace = tokenizer.decode(example_tokenized['input_ids'][0, tokenid_perturb].cpu().numpy())\n",
    "# K = 10 # number of potential antonym\n",
    "\n",
    "# if word2replace not in stop_words:\n",
    "#     word2replace_id = word_id_dict[word2replace]\n",
    "#     word_emb = word_sim_embeddings[word2replace_id]\n",
    "#     K_antonym_id = np.argsort(np.abs(np.dot(word_sim_embeddings, word_emb.reshape(-1, 1)).reshape(-1)))[:K]\n",
    "#     print(K_antonym_id)\n",
    "#     for ant_id in K_antonym_id:\n",
    "#         print(id_word_dict[ant_id])\n",
    "#     #print(np.sort(np.dot(word_sim_embeddings, word_emb.reshape(-1, 1)).reshape(-1))[:K])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
